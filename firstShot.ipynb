{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary torch and torchvision libraries\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and load the CIFAR-10 dataset\n",
    "train_data = CIFAR10(root='./data', \n",
    "                     train=True, \n",
    "                     download=True, \n",
    "                     transform=transforms.ToTensor())\n",
    "\n",
    "test_data = CIFAR10(root='./data',\n",
    "                    train=False,\n",
    "                    download=True,\n",
    "                    transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See classes\n",
    "class_names = train_data.classes\n",
    "print(class_names) # It is also idx to class -> class_names[1] = 'Trouser\n",
    "# Class to index\n",
    "cls_to_idx = train_data.class_to_idx\n",
    "print(cls_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataLoader object to load data in batches\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data,\n",
    "                                           batch_size=32,\n",
    "                                           shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_data,\n",
    "                                            batch_size=32,\n",
    "                                            shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(MyCNN, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2), # output: 64 x 16 x 16\n",
    "\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2), # output: 128 x 8 x 8\n",
    "\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2), # output: 256 x 4 x 4\n",
    "\n",
    "            nn.Flatten(), \n",
    "            nn.Linear(in_features=256*4*4, out_features=1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=1024, out_features=512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=512, out_features=num_classes))\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "firstModel = MyCNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import accuracy metric\n",
    "from torchmetrics import Accuracy\n",
    "accuracy = Accuracy(task=\"multiclass\", num_classes=len(class_names)).to(device)\n",
    "# Setup loss function and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=firstModel.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model: torch.nn.Module,\n",
    "               data_loader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               accuracy,\n",
    "               device: torch.device = device):\n",
    "    train_loss, train_acc = 0, 0\n",
    "    model.to(device)\n",
    "    \n",
    "    for batch, (X, y) in enumerate(data_loader):\n",
    "        \n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        # Training\n",
    "        model.train()\n",
    "        # Forward pass\n",
    "        y_pred = model(X)\n",
    "        # Calculate loss per batch\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss # accumulate loss per batch\n",
    "        # Update accuracy\n",
    "        accuracy.update(y_pred, y)\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "        # Print loss every 400 batches\n",
    "        if batch % 400 == 0:\n",
    "            print(f\"Looked at {batch * len(X)}/{len(data_loader.dataset)} samples\")\n",
    "    # Loss per epoch    \n",
    "    train_loss = train_loss / len(data_loader)\n",
    "    train_acc = accuracy.compute()\n",
    "    print(f\"Train loss: {train_loss:.5f} | Train accuracy: {train_acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using tqdm for progress bar\n",
    "from tqdm.auto import tqdm\n",
    "torch.manual_seed(42)\n",
    "\n",
    "epochs = 8\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    \n",
    "    print(f\"Epoch: {epoch}\\n---------\")\n",
    "    \n",
    "    train_step(model=firstModel, \n",
    "        data_loader=train_loader, \n",
    "        loss_fn=loss_fn,\n",
    "        optimizer=optimizer,\n",
    "        accuracy=accuracy)\n",
    "    \n",
    "    test_step(model=firstModel,\n",
    "        data_loader=test_loader,\n",
    "        loss_fn=loss_fn,\n",
    "        accuracy=accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
