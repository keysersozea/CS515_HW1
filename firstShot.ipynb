{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary torch and torchvision libraries\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Download and load the CIFAR-10 dataset\n",
    "train_data = CIFAR10(root='./data', \n",
    "                     train=True, \n",
    "                     download=True, \n",
    "                     transform=transforms.ToTensor())\n",
    "\n",
    "test_data = CIFAR10(root='./data',\n",
    "                    train=False,\n",
    "                    download=True,\n",
    "                    transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
      "{'airplane': 0, 'automobile': 1, 'bird': 2, 'cat': 3, 'deer': 4, 'dog': 5, 'frog': 6, 'horse': 7, 'ship': 8, 'truck': 9}\n"
     ]
    }
   ],
   "source": [
    "# See classes\n",
    "class_names = train_data.classes\n",
    "print(class_names) # It is also idx to class -> class_names[1] = 'Trouser\n",
    "# Class to index\n",
    "cls_to_idx = train_data.class_to_idx\n",
    "print(cls_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataLoader object to load data in batches\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data,\n",
    "                                           batch_size=32,\n",
    "                                           shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_data,\n",
    "                                            batch_size=32,\n",
    "                                            shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(MyCNN, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2), # output: 64 x 16 x 16\n",
    "\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2), # output: 128 x 8 x 8\n",
    "\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2), # output: 256 x 4 x 4\n",
    "\n",
    "            nn.Flatten(), \n",
    "            nn.Linear(in_features=256*4*4, out_features=1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=1024, out_features=512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=512, out_features=num_classes))\n",
    "        \n",
    "        self.init_weights()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "    def init_weights(self):\n",
    "            for m in self.modules(): # self.modules() iterates through all modules (layers) in the model, including nested ones, allowing for operations like weight initialization to be applied universally.\n",
    "                if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "                    nn.init.kaiming_uniform_(m.weight, mode='fan_in', nonlinearity='relu')\n",
    "                    if m.bias is not None:\n",
    "                        nn.init.constant_(m.bias, 0)\n",
    "firstModel = MyCNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import accuracy metric\n",
    "from torchmetrics import Accuracy\n",
    "accuracy = Accuracy(task=\"multiclass\", num_classes=len(class_names)).to(device)\n",
    "# Setup loss function and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params=firstModel.parameters(), lr=0.003494286840772853, momentum= 0.9421216112061177)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model: torch.nn.Module,\n",
    "               data_loader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               accuracy,\n",
    "               device: torch.device = device):\n",
    "    \n",
    "    accuracy.reset()\n",
    "    train_loss, train_acc = 0, 0\n",
    "    model.to(device)\n",
    "    \n",
    "    for batch, (X, y) in enumerate(data_loader):\n",
    "        \n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        # Training\n",
    "        model.train()\n",
    "        # Forward pass\n",
    "        y_pred = model(X)\n",
    "        # Calculate loss per batch\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss # accumulate loss per batch\n",
    "        # Update accuracy\n",
    "        accuracy.update(y_pred, y)\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "    # Loss per epoch    \n",
    "    train_loss = train_loss / len(data_loader)\n",
    "    train_acc = accuracy.compute()\n",
    "    print(f\"Train loss: {train_loss:.5f} | Train accuracy: {train_acc*100:.2f}%\")\n",
    "    return train_loss, train_acc\n",
    "\n",
    "def test_step(model: torch.nn.Module,\n",
    "              data_loader: torch.utils.data.DataLoader,\n",
    "              loss_fn: torch.nn.Module,\n",
    "              accuracy,\n",
    "              device: torch.device = device):\n",
    "    \n",
    "    \n",
    "    accuracy.reset()\n",
    "    ## Testing\n",
    "    test_loss, test_acc = 0, 0\n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "    # Turn off gradients\n",
    "    with torch.inference_mode():\n",
    "        for X, y in data_loader:\n",
    "            # Move data to device\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            # Forward pass\n",
    "            test_pred = model(X)\n",
    "            # Calculate loss per batch\n",
    "            test_loss += loss_fn(test_pred, y)\n",
    "            # Update accuracy\n",
    "            accuracy.update(test_pred, y)\n",
    "    # Loss per epoch        \n",
    "    test_loss = test_loss / len(data_loader)\n",
    "    # Calculate accuracy\n",
    "    test_acc = accuracy.compute()\n",
    "    # Print loss and accuracy per epoch\n",
    "    print(f\"Test loss: {test_loss:.5f}, Test acc: {test_acc*100:.2f}%\\n\")\n",
    "    return test_loss, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "---------\n",
      "Train loss: 1.33210 | Train accuracy: 51.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 1/8 [00:30<03:34, 30.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.13906, Test acc: 59.38%\n",
      "\n",
      "Epoch: 1\n",
      "---------\n",
      "Train loss: 0.88828 | Train accuracy: 68.68%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 2/8 [01:00<03:01, 30.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.83717, Test acc: 70.72%\n",
      "\n",
      "Epoch: 2\n",
      "---------\n",
      "Train loss: 0.67992 | Train accuracy: 76.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 3/8 [01:31<02:32, 30.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.71144, Test acc: 75.90%\n",
      "\n",
      "Epoch: 3\n",
      "---------\n",
      "Train loss: 0.52435 | Train accuracy: 81.48%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 4/8 [02:02<02:02, 30.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.69600, Test acc: 76.78%\n",
      "\n",
      "Epoch: 4\n",
      "---------\n",
      "Train loss: 0.40177 | Train accuracy: 86.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 5/8 [02:33<01:32, 30.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.79350, Test acc: 75.01%\n",
      "\n",
      "Epoch: 5\n",
      "---------\n",
      "Train loss: 0.29994 | Train accuracy: 89.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 6/8 [03:03<01:01, 30.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.74419, Test acc: 77.16%\n",
      "\n",
      "Epoch: 6\n",
      "---------\n",
      "Train loss: 0.22747 | Train accuracy: 92.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 7/8 [03:33<00:30, 30.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.74773, Test acc: 77.72%\n",
      "\n",
      "Epoch: 7\n",
      "---------\n",
      "Train loss: 0.17305 | Train accuracy: 94.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [04:03<00:00, 30.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.85540, Test acc: 79.09%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Using tqdm for progress bar\n",
    "from tqdm.auto import tqdm\n",
    "torch.manual_seed(42)\n",
    "\n",
    "epochs = 8\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    \n",
    "    print(f\"Epoch: {epoch}\\n---------\")\n",
    "    \n",
    "    train_step(model=firstModel, \n",
    "        data_loader=train_loader, \n",
    "        loss_fn=loss_fn,\n",
    "        optimizer=optimizer,\n",
    "        accuracy=accuracy)\n",
    "    \n",
    "    test_step(model=firstModel,\n",
    "        data_loader=test_loader,\n",
    "        loss_fn=loss_fn,\n",
    "        accuracy=accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
