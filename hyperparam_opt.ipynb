{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aliyilmaz/anaconda3/envs/pytorch_env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import necessary torch and torchvision libraries\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import optuna\n",
    "\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Download and load the CIFAR-10 dataset\n",
    "train_data = CIFAR10(root='./data', \n",
    "                     train=True, \n",
    "                     download=True, \n",
    "                     transform=transforms.ToTensor())\n",
    "\n",
    "test_data = CIFAR10(root='./data',\n",
    "                    train=False,\n",
    "                    download=True,\n",
    "                    transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
      "{'airplane': 0, 'automobile': 1, 'bird': 2, 'cat': 3, 'deer': 4, 'dog': 5, 'frog': 6, 'horse': 7, 'ship': 8, 'truck': 9}\n"
     ]
    }
   ],
   "source": [
    "# See classes\n",
    "class_names = train_data.classes\n",
    "print(class_names) # It is also idx to class -> class_names[1] = 'Trouser\n",
    "# Class to index\n",
    "cls_to_idx = train_data.class_to_idx\n",
    "print(cls_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataLoader object to load data in batches\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data,\n",
    "                                           batch_size=32,\n",
    "                                           shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_data,\n",
    "                                            batch_size=32,\n",
    "                                            shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scheduler(optimizer, scheduler_name):\n",
    "    if scheduler_name == 'StepLR':\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1) # Each 5 epochs, the learning rate is multiplied by gamma\n",
    "    elif scheduler_name == 'ExponentialLR':\n",
    "        scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.8) # The learning rate is multiplied by gamma every epoch\n",
    "    else:  # CosineAnnealingLR\n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "    return scheduler\n",
    "\n",
    "def suggest_hyperparameters(trial):\n",
    "    params = {\n",
    "        'scheduler_name': trial.suggest_categorical('scheduler_name', ['StepLR', 'ExponentialLR', 'CosineAnnealingLR']), # \n",
    "        'optimizer_name': trial.suggest_categorical('optimizer', ['SGD', 'Adam', 'RMSprop']),\n",
    "        'lr': trial.suggest_float('lr', 5*1e-5, 5*1e-3),\n",
    "        'momentum': 0.0,\n",
    "        'init_method': trial.suggest_categorical('init_method', ['xavier_uniform', 'he', 'trunc_normal'])\n",
    "    }\n",
    "    \n",
    "    if params['optimizer_name'] == 'SGD':\n",
    "        params['momentum'] = trial.suggest_float('momentum', 0.85, 0.99)\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mMyCNN\u001b[39;00m(\u001b[43mnn\u001b[49m\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, init_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxavier_uniform\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;28msuper\u001b[39m(MyCNN, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class MyCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10, init_method='xavier_uniform'):\n",
    "        super(MyCNN, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2), # output: 64 x 16 x 16\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2), # output: 128 x 8 x 8\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2), # output: 256 x 4 x 4\n",
    "\n",
    "            nn.Flatten(), \n",
    "            nn.Linear(256*4*4, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, num_classes))\n",
    "        self.init_weights(init_method)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.network(x)\n",
    "        return x\n",
    "    \n",
    "    def init_weights(self, init_method):\n",
    "        if init_method == 'xavier_uniform':\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "                    nn.init.xavier_uniform_(m.weight)\n",
    "                    if m.bias is not None:\n",
    "                        nn.init.constant_(m.bias, 0)\n",
    "        elif init_method == 'he':\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "                    nn.init.kaiming_uniform_(m.weight, mode='fan_in', nonlinearity='relu')\n",
    "                    if m.bias is not None:\n",
    "                        nn.init.constant_(m.bias, 0)\n",
    "        elif init_method == 'trunc_normal':\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "                    nn.init.trunc_normal_(m.weight, mean=0.0, std=0.1)\n",
    "                    if m.bias is not None:\n",
    "                        nn.init.constant_(m.bias, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'device' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_step\u001b[39m(model: torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule,\n\u001b[1;32m      2\u001b[0m                data_loader: torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader,\n\u001b[1;32m      3\u001b[0m                loss_fn: torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule,\n\u001b[1;32m      4\u001b[0m                optimizer: torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mOptimizer,\n\u001b[1;32m      5\u001b[0m                accuracy,\n\u001b[0;32m----> 6\u001b[0m                device: torch\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m \u001b[43mdevice\u001b[49m):\n\u001b[1;32m      8\u001b[0m     accuracy\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m      9\u001b[0m     train_loss, train_acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'device' is not defined"
     ]
    }
   ],
   "source": [
    "def train_step(model: torch.nn.Module,\n",
    "               data_loader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               accuracy,\n",
    "               device: torch.device = device):\n",
    "    \n",
    "    accuracy.reset()\n",
    "    train_loss, train_acc = 0, 0\n",
    "    model.to(device)\n",
    "    \n",
    "    for batch, (X, y) in enumerate(data_loader):\n",
    "        \n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        # Training\n",
    "        model.train()\n",
    "        # Forward pass\n",
    "        y_pred = model(X)\n",
    "        # Calculate loss per batch\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss # accumulate loss per batch\n",
    "        # Update accuracy\n",
    "        accuracy.update(y_pred, y)\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "    # Loss per epoch    \n",
    "    train_loss = train_loss / len(data_loader)\n",
    "    train_acc = accuracy.compute()\n",
    "    print(f\"Train loss: {train_loss:.5f} | Train accuracy: {train_acc*100:.2f}%\")\n",
    "    return train_loss, train_acc\n",
    "\n",
    "def test_step(model: torch.nn.Module,\n",
    "              data_loader: torch.utils.data.DataLoader,\n",
    "              loss_fn: torch.nn.Module,\n",
    "              accuracy,\n",
    "              device: torch.device = device):\n",
    "    \n",
    "    \n",
    "    accuracy.reset()\n",
    "    ## Testing\n",
    "    test_loss, test_acc = 0, 0\n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "    # Turn off gradients\n",
    "    with torch.inference_mode():\n",
    "        for X, y in data_loader:\n",
    "            # Move data to device\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            # Forward pass\n",
    "            test_pred = model(X)\n",
    "            # Calculate loss per batch\n",
    "            test_loss += loss_fn(test_pred, y)\n",
    "            # Update accuracy\n",
    "            accuracy.update(test_pred, y)\n",
    "    # Loss per epoch        \n",
    "    test_loss = test_loss / len(data_loader)\n",
    "    # Calculate accuracy\n",
    "    test_acc = accuracy.compute()\n",
    "    # Print loss and accuracy per epoch\n",
    "    print(f\"Test loss: {test_loss:.5f}, Test acc: {test_acc*100:.2f}%\\n\")\n",
    "    return test_loss, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import accuracy metric\n",
    "from torchmetrics import Accuracy\n",
    "accuracy = Accuracy(task=\"multiclass\", num_classes=10).to(device)\n",
    "# Setup loss function and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \n",
    "    params = suggest_hyperparameters(trial)\n",
    "    \n",
    "    model = MyCNN(num_classes=10, init_method=params['init_method'])\n",
    "    \n",
    "    if params['optimizer_name'] == 'SGD':\n",
    "        optimizer = getattr(optim, params['optimizer_name'])(model.parameters(), lr=params['lr'], momentum=params['momentum']) \n",
    "    else:\n",
    "        optimizer = getattr(optim, params['optimizer_name'])(model.parameters(), lr=params['lr'])\n",
    "        \n",
    "    scheduler = get_scheduler(optimizer, params['scheduler_name']) \n",
    "    \n",
    "    print(f\"Optimizer: {params['optimizer_name']}, Scheduler: {params['scheduler_name']}, Learning rate: {params['lr']}, Momentum: {params['momentum']}, Init method: {params['init_method']}\")\n",
    "    \n",
    "    \"\"\"\n",
    "    model = MyCNN(num_classes=10, init_method='he')\n",
    "    optimizer = torch.optim.Adam(params=model.parameters(), lr=0.001)\n",
    "    \"\"\"\n",
    "    epochs = 4\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
    "        train_loss, train_acc = train_step(model, train_loader, loss_fn, optimizer, accuracy)\n",
    "        test_loss, test_acc = test_step(model, test_loader, loss_fn, accuracy)\n",
    "        scheduler.step()\n",
    "    return test_loss\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "print('Best trial:')\n",
    "trial = study.best_trial\n",
    "\n",
    "print(f'Value: {trial.value}')\n",
    "print('Params: ')\n",
    "for key, value in trial.params.items():\n",
    "    print(f'{key}: {value}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mention that, getting better loss values does not mean getting higher accuracy. Therefore, optimization and also analysis should be based on accuracy value. In overtrain situations, loss value can be too high but accuracy value might be converge at higher value than expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)\n",
    "\n",
    "optuna.visualization.plot_parallel_coordinate(study)\n",
    "\n",
    "optuna.visualization.plot_param_importances(study)\n",
    "\n",
    "optuna.visualization.plot_slice(study)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial #0, Value: 0.7659769058227539\n",
      "Params: \n",
      "    scheduler_name: CosineAnnealingLR\n",
      "    optimizer: RMSprop\n",
      "    lr: 0.0008694247141217115\n",
      "    scheduler: ExponentialLR\n",
      "    init_method: xavier_uniform\n",
      "Trial #1, Value: 2.302717924118042\n",
      "Params: \n",
      "    scheduler_name: ExponentialLR\n",
      "    optimizer: RMSprop\n",
      "    lr: 0.0038758303225686947\n",
      "    scheduler: CosineAnnealingLR\n",
      "    init_method: he\n",
      "Trial #2, Value: 0.7388409376144409\n",
      "Params: \n",
      "    scheduler_name: ExponentialLR\n",
      "    optimizer: SGD\n",
      "    lr: 0.006258877494227019\n",
      "    scheduler: CosineAnnealingLR\n",
      "    init_method: he\n",
      "    momentum: 0.9616413678752236\n",
      "Trial #3, Value: 2.302915096282959\n",
      "Params: \n",
      "    scheduler_name: ExponentialLR\n",
      "    optimizer: RMSprop\n",
      "    lr: 0.007354517860952842\n",
      "    scheduler: CosineAnnealingLR\n",
      "    init_method: he\n",
      "Trial #4, Value: 0.6918030977249146\n",
      "Params: \n",
      "    scheduler_name: StepLR\n",
      "    optimizer: Adam\n",
      "    lr: 0.0006813271445328782\n",
      "    scheduler: StepLR\n",
      "    init_method: xavier_uniform\n",
      "Trial #5, Value: None\n",
      "Params: \n",
      "    scheduler_name: StepLR\n",
      "    optimizer: Adam\n",
      "    lr: 0.007015541333737277\n",
      "    scheduler: CosineAnnealingLR\n",
      "    init_method: he\n"
     ]
    }
   ],
   "source": [
    "# `study` değişkeni, optimize edilmiş Optuna study nesnesidir.\n",
    "\n",
    "for trial in study.trials:\n",
    "    print(f\"Trial #{trial.number}, Value: {trial.value}\")\n",
    "    print(\"Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(f\"    {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   number     value             datetime_start          datetime_complete  \\\n",
      "0       0  0.765977 2024-03-19 13:57:21.711175 2024-03-19 13:59:34.548201   \n",
      "1       1  2.302718 2024-03-19 13:59:34.548774 2024-03-19 14:01:49.329503   \n",
      "2       2  0.738841 2024-03-19 14:01:49.330536 2024-03-19 14:03:54.906295   \n",
      "3       3  2.302915 2024-03-19 14:03:54.906965 2024-03-19 14:06:07.788106   \n",
      "4       4  0.691803 2024-03-19 14:06:07.788751 2024-03-19 14:08:30.116511   \n",
      "5       5       NaN 2024-03-19 14:08:30.117051 2024-03-19 14:09:21.629978   \n",
      "\n",
      "                duration params_init_method  params_lr  params_momentum  \\\n",
      "0 0 days 00:02:12.837026     xavier_uniform   0.000869              NaN   \n",
      "1 0 days 00:02:14.780729                 he   0.003876              NaN   \n",
      "2 0 days 00:02:05.575759                 he   0.006259         0.961641   \n",
      "3 0 days 00:02:12.881141                 he   0.007355              NaN   \n",
      "4 0 days 00:02:22.327760     xavier_uniform   0.000681              NaN   \n",
      "5 0 days 00:00:51.512927                 he   0.007016              NaN   \n",
      "\n",
      "  params_optimizer   params_scheduler params_scheduler_name     state  \n",
      "0          RMSprop      ExponentialLR     CosineAnnealingLR  COMPLETE  \n",
      "1          RMSprop  CosineAnnealingLR         ExponentialLR  COMPLETE  \n",
      "2              SGD  CosineAnnealingLR         ExponentialLR  COMPLETE  \n",
      "3          RMSprop  CosineAnnealingLR         ExponentialLR  COMPLETE  \n",
      "4             Adam             StepLR                StepLR  COMPLETE  \n",
      "5             Adam  CosineAnnealingLR                StepLR      FAIL  \n"
     ]
    }
   ],
   "source": [
    "df = study.trials_dataframe()\n",
    "\n",
    "# Set dataframe column width option\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('hyperparameter_optimization_results1.csv')\n",
    "df2 = pd.read_csv('hyperparameter_optimization_results2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.drop(columns=['datetime_complete'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv('hyperparameter_optimization_results1.csv', index=False)\n",
    "df2.to_csv('hyperparameter_optimization_results2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_init_method</th>\n",
       "      <th>params_lr</th>\n",
       "      <th>params_momentum</th>\n",
       "      <th>params_optimizer</th>\n",
       "      <th>params_scheduler</th>\n",
       "      <th>params_scheduler_name</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.302589</td>\n",
       "      <td>0 days 00:02:01.987918</td>\n",
       "      <td>trunc_normal</td>\n",
       "      <td>0.000518</td>\n",
       "      <td>0.892873</td>\n",
       "      <td>SGD</td>\n",
       "      <td>StepLR</td>\n",
       "      <td>StepLR</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.942960</td>\n",
       "      <td>0 days 00:02:04.031166</td>\n",
       "      <td>xavier_uniform</td>\n",
       "      <td>0.002231</td>\n",
       "      <td>0.910243</td>\n",
       "      <td>SGD</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>StepLR</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.925347</td>\n",
       "      <td>0 days 00:02:07.265297</td>\n",
       "      <td>trunc_normal</td>\n",
       "      <td>0.002499</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>StepLR</td>\n",
       "      <td>CosineAnnealingLR</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.302594</td>\n",
       "      <td>0 days 00:02:09.839847</td>\n",
       "      <td>xavier_uniform</td>\n",
       "      <td>0.002081</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adam</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>CosineAnnealingLR</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.302613</td>\n",
       "      <td>0 days 00:02:09.941922</td>\n",
       "      <td>xavier_uniform</td>\n",
       "      <td>0.002995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adam</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>CosineAnnealingLR</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.303319</td>\n",
       "      <td>0 days 00:02:03.659195</td>\n",
       "      <td>xavier_uniform</td>\n",
       "      <td>0.004710</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>CosineAnnealingLR</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.852053</td>\n",
       "      <td>0 days 00:02:02.687114</td>\n",
       "      <td>he</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>0.909065</td>\n",
       "      <td>SGD</td>\n",
       "      <td>StepLR</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.138596</td>\n",
       "      <td>0 days 00:02:13.593366</td>\n",
       "      <td>he</td>\n",
       "      <td>0.000904</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adam</td>\n",
       "      <td>StepLR</td>\n",
       "      <td>CosineAnnealingLR</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.035344</td>\n",
       "      <td>0 days 00:02:01.980483</td>\n",
       "      <td>he</td>\n",
       "      <td>0.004148</td>\n",
       "      <td>0.901259</td>\n",
       "      <td>SGD</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>StepLR</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.849720</td>\n",
       "      <td>0 days 00:02:12.674130</td>\n",
       "      <td>xavier_uniform</td>\n",
       "      <td>0.000856</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adam</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>StepLR</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.882345</td>\n",
       "      <td>0 days 00:02:11.721073</td>\n",
       "      <td>xavier_uniform</td>\n",
       "      <td>0.001529</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adam</td>\n",
       "      <td>CosineAnnealingLR</td>\n",
       "      <td>StepLR</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.747812</td>\n",
       "      <td>0 days 00:02:02.656052</td>\n",
       "      <td>he</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.989470</td>\n",
       "      <td>SGD</td>\n",
       "      <td>StepLR</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.879680</td>\n",
       "      <td>0 days 00:02:01.935187</td>\n",
       "      <td>he</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.987752</td>\n",
       "      <td>SGD</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.920025</td>\n",
       "      <td>0 days 00:02:12.731965</td>\n",
       "      <td>he</td>\n",
       "      <td>0.001353</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adam</td>\n",
       "      <td>StepLR</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.954615</td>\n",
       "      <td>0 days 00:02:06.692369</td>\n",
       "      <td>trunc_normal</td>\n",
       "      <td>0.001128</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>CosineAnnealingLR</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.976881</td>\n",
       "      <td>0 days 00:02:00.828639</td>\n",
       "      <td>xavier_uniform</td>\n",
       "      <td>0.003179</td>\n",
       "      <td>0.983258</td>\n",
       "      <td>SGD</td>\n",
       "      <td>StepLR</td>\n",
       "      <td>StepLR</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.867235</td>\n",
       "      <td>0 days 00:02:14.842837</td>\n",
       "      <td>he</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adam</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>StepLR</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.049564</td>\n",
       "      <td>0 days 00:02:01.691782</td>\n",
       "      <td>he</td>\n",
       "      <td>0.001823</td>\n",
       "      <td>0.951815</td>\n",
       "      <td>SGD</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.921515</td>\n",
       "      <td>0 days 00:02:13.151225</td>\n",
       "      <td>xavier_uniform</td>\n",
       "      <td>0.000786</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adam</td>\n",
       "      <td>StepLR</td>\n",
       "      <td>StepLR</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.185550</td>\n",
       "      <td>0 days 00:02:04.976775</td>\n",
       "      <td>trunc_normal</td>\n",
       "      <td>0.003152</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>CosineAnnealingLR</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.335523</td>\n",
       "      <td>0 days 00:02:02.862222</td>\n",
       "      <td>xavier_uniform</td>\n",
       "      <td>0.000603</td>\n",
       "      <td>0.855895</td>\n",
       "      <td>SGD</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>StepLR</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.827636</td>\n",
       "      <td>0 days 00:02:02.553706</td>\n",
       "      <td>he</td>\n",
       "      <td>0.000412</td>\n",
       "      <td>0.942698</td>\n",
       "      <td>SGD</td>\n",
       "      <td>StepLR</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.761643</td>\n",
       "      <td>0 days 00:02:02.574439</td>\n",
       "      <td>he</td>\n",
       "      <td>0.001086</td>\n",
       "      <td>0.949152</td>\n",
       "      <td>SGD</td>\n",
       "      <td>StepLR</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.989199</td>\n",
       "      <td>0 days 00:02:02.199857</td>\n",
       "      <td>he</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.949549</td>\n",
       "      <td>SGD</td>\n",
       "      <td>StepLR</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.825063</td>\n",
       "      <td>0 days 00:02:03.041084</td>\n",
       "      <td>he</td>\n",
       "      <td>0.001513</td>\n",
       "      <td>0.948067</td>\n",
       "      <td>SGD</td>\n",
       "      <td>StepLR</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.862663</td>\n",
       "      <td>0 days 00:02:03.550963</td>\n",
       "      <td>he</td>\n",
       "      <td>0.001683</td>\n",
       "      <td>0.964365</td>\n",
       "      <td>SGD</td>\n",
       "      <td>StepLR</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.759245</td>\n",
       "      <td>0 days 00:02:03.186581</td>\n",
       "      <td>he</td>\n",
       "      <td>0.001310</td>\n",
       "      <td>0.930871</td>\n",
       "      <td>SGD</td>\n",
       "      <td>StepLR</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.750270</td>\n",
       "      <td>0 days 00:02:03.822107</td>\n",
       "      <td>he</td>\n",
       "      <td>0.001223</td>\n",
       "      <td>0.929150</td>\n",
       "      <td>SGD</td>\n",
       "      <td>StepLR</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.789683</td>\n",
       "      <td>0 days 00:02:02.489306</td>\n",
       "      <td>he</td>\n",
       "      <td>0.002032</td>\n",
       "      <td>0.929102</td>\n",
       "      <td>SGD</td>\n",
       "      <td>StepLR</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0 days 00:01:59.720479</td>\n",
       "      <td>trunc_normal</td>\n",
       "      <td>0.002714</td>\n",
       "      <td>0.878635</td>\n",
       "      <td>SGD</td>\n",
       "      <td>StepLR</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0 days 00:02:00.037696</td>\n",
       "      <td>trunc_normal</td>\n",
       "      <td>0.003684</td>\n",
       "      <td>0.878018</td>\n",
       "      <td>SGD</td>\n",
       "      <td>StepLR</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0 days 00:01:59.857433</td>\n",
       "      <td>trunc_normal</td>\n",
       "      <td>0.002722</td>\n",
       "      <td>0.884040</td>\n",
       "      <td>SGD</td>\n",
       "      <td>StepLR</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2.302586</td>\n",
       "      <td>0 days 00:01:59.193714</td>\n",
       "      <td>trunc_normal</td>\n",
       "      <td>0.000540</td>\n",
       "      <td>0.880970</td>\n",
       "      <td>SGD</td>\n",
       "      <td>StepLR</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.952630</td>\n",
       "      <td>0 days 00:02:02.931586</td>\n",
       "      <td>he</td>\n",
       "      <td>0.002658</td>\n",
       "      <td>0.973165</td>\n",
       "      <td>SGD</td>\n",
       "      <td>StepLR</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.765809</td>\n",
       "      <td>0 days 00:02:02.420834</td>\n",
       "      <td>he</td>\n",
       "      <td>0.001160</td>\n",
       "      <td>0.928068</td>\n",
       "      <td>SGD</td>\n",
       "      <td>StepLR</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.770081</td>\n",
       "      <td>0 days 00:02:03.293866</td>\n",
       "      <td>he</td>\n",
       "      <td>0.001173</td>\n",
       "      <td>0.929322</td>\n",
       "      <td>SGD</td>\n",
       "      <td>StepLR</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.865328</td>\n",
       "      <td>0 days 00:02:02.679422</td>\n",
       "      <td>he</td>\n",
       "      <td>0.002483</td>\n",
       "      <td>0.966672</td>\n",
       "      <td>SGD</td>\n",
       "      <td>StepLR</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.789810</td>\n",
       "      <td>0 days 00:02:02.810039</td>\n",
       "      <td>he</td>\n",
       "      <td>0.000884</td>\n",
       "      <td>0.939569</td>\n",
       "      <td>SGD</td>\n",
       "      <td>StepLR</td>\n",
       "      <td>CosineAnnealingLR</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.760163</td>\n",
       "      <td>0 days 00:02:02.906396</td>\n",
       "      <td>he</td>\n",
       "      <td>0.001917</td>\n",
       "      <td>0.921222</td>\n",
       "      <td>SGD</td>\n",
       "      <td>StepLR</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.892873</td>\n",
       "      <td>0 days 00:02:06.373475</td>\n",
       "      <td>trunc_normal</td>\n",
       "      <td>0.002247</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>StepLR</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.780917</td>\n",
       "      <td>0 days 00:02:03.868736</td>\n",
       "      <td>he</td>\n",
       "      <td>0.001801</td>\n",
       "      <td>0.916119</td>\n",
       "      <td>SGD</td>\n",
       "      <td>StepLR</td>\n",
       "      <td>CosineAnnealingLR</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.888090</td>\n",
       "      <td>0 days 00:02:02.254512</td>\n",
       "      <td>he</td>\n",
       "      <td>0.003799</td>\n",
       "      <td>0.879619</td>\n",
       "      <td>SGD</td>\n",
       "      <td>CosineAnnealingLR</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.873460</td>\n",
       "      <td>0 days 00:02:07.727737</td>\n",
       "      <td>he</td>\n",
       "      <td>0.002781</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>StepLR</td>\n",
       "      <td>CosineAnnealingLR</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.836241</td>\n",
       "      <td>0 days 00:02:02.386805</td>\n",
       "      <td>he</td>\n",
       "      <td>0.002223</td>\n",
       "      <td>0.923838</td>\n",
       "      <td>SGD</td>\n",
       "      <td>StepLR</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.746500</td>\n",
       "      <td>0 days 00:02:02.781243</td>\n",
       "      <td>he</td>\n",
       "      <td>0.001351</td>\n",
       "      <td>0.938136</td>\n",
       "      <td>SGD</td>\n",
       "      <td>StepLR</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.778868</td>\n",
       "      <td>0 days 00:02:02.107878</td>\n",
       "      <td>he</td>\n",
       "      <td>0.001427</td>\n",
       "      <td>0.935816</td>\n",
       "      <td>SGD</td>\n",
       "      <td>StepLR</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.824558</td>\n",
       "      <td>0 days 00:02:03.396844</td>\n",
       "      <td>he</td>\n",
       "      <td>0.001977</td>\n",
       "      <td>0.917851</td>\n",
       "      <td>SGD</td>\n",
       "      <td>StepLR</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.861688</td>\n",
       "      <td>0 days 00:02:02.327933</td>\n",
       "      <td>he</td>\n",
       "      <td>0.001671</td>\n",
       "      <td>0.959372</td>\n",
       "      <td>SGD</td>\n",
       "      <td>StepLR</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.727430</td>\n",
       "      <td>0 days 00:02:03.112748</td>\n",
       "      <td>he</td>\n",
       "      <td>0.001345</td>\n",
       "      <td>0.897994</td>\n",
       "      <td>SGD</td>\n",
       "      <td>StepLR</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0 days 00:01:59.470721</td>\n",
       "      <td>trunc_normal</td>\n",
       "      <td>0.000783</td>\n",
       "      <td>0.895435</td>\n",
       "      <td>SGD</td>\n",
       "      <td>CosineAnnealingLR</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       value                duration params_init_method  params_lr  \\\n",
       "0   2.302589  0 days 00:02:01.987918       trunc_normal   0.000518   \n",
       "1   0.942960  0 days 00:02:04.031166     xavier_uniform   0.002231   \n",
       "2   0.925347  0 days 00:02:07.265297       trunc_normal   0.002499   \n",
       "3   2.302594  0 days 00:02:09.839847     xavier_uniform   0.002081   \n",
       "4   2.302613  0 days 00:02:09.941922     xavier_uniform   0.002995   \n",
       "5   2.303319  0 days 00:02:03.659195     xavier_uniform   0.004710   \n",
       "6   0.852053  0 days 00:02:02.687114                 he   0.000379   \n",
       "7   1.138596  0 days 00:02:13.593366                 he   0.000904   \n",
       "8   1.035344  0 days 00:02:01.980483                 he   0.004148   \n",
       "9   0.849720  0 days 00:02:12.674130     xavier_uniform   0.000856   \n",
       "10  0.882345  0 days 00:02:11.721073     xavier_uniform   0.001529   \n",
       "11  0.747812  0 days 00:02:02.656052                 he   0.000101   \n",
       "12  0.879680  0 days 00:02:01.935187                 he   0.000069   \n",
       "13  0.920025  0 days 00:02:12.731965                 he   0.001353   \n",
       "14  0.954615  0 days 00:02:06.692369       trunc_normal   0.001128   \n",
       "15  0.976881  0 days 00:02:00.828639     xavier_uniform   0.003179   \n",
       "16  0.867235  0 days 00:02:14.842837                 he   0.000080   \n",
       "17  1.049564  0 days 00:02:01.691782                 he   0.001823   \n",
       "18  0.921515  0 days 00:02:13.151225     xavier_uniform   0.000786   \n",
       "19  1.185550  0 days 00:02:04.976775       trunc_normal   0.003152   \n",
       "20  1.335523  0 days 00:02:02.862222     xavier_uniform   0.000603   \n",
       "21  0.827636  0 days 00:02:02.553706                 he   0.000412   \n",
       "22  0.761643  0 days 00:02:02.574439                 he   0.001086   \n",
       "23  0.989199  0 days 00:02:02.199857                 he   0.000101   \n",
       "24  0.825063  0 days 00:02:03.041084                 he   0.001513   \n",
       "25  0.862663  0 days 00:02:03.550963                 he   0.001683   \n",
       "26  0.759245  0 days 00:02:03.186581                 he   0.001310   \n",
       "27  0.750270  0 days 00:02:03.822107                 he   0.001223   \n",
       "28  0.789683  0 days 00:02:02.489306                 he   0.002032   \n",
       "29       NaN  0 days 00:01:59.720479       trunc_normal   0.002714   \n",
       "30       NaN  0 days 00:02:00.037696       trunc_normal   0.003684   \n",
       "31       NaN  0 days 00:01:59.857433       trunc_normal   0.002722   \n",
       "32  2.302586  0 days 00:01:59.193714       trunc_normal   0.000540   \n",
       "33  0.952630  0 days 00:02:02.931586                 he   0.002658   \n",
       "34  0.765809  0 days 00:02:02.420834                 he   0.001160   \n",
       "35  0.770081  0 days 00:02:03.293866                 he   0.001173   \n",
       "36  0.865328  0 days 00:02:02.679422                 he   0.002483   \n",
       "37  0.789810  0 days 00:02:02.810039                 he   0.000884   \n",
       "38  0.760163  0 days 00:02:02.906396                 he   0.001917   \n",
       "39  0.892873  0 days 00:02:06.373475       trunc_normal   0.002247   \n",
       "40  0.780917  0 days 00:02:03.868736                 he   0.001801   \n",
       "41  0.888090  0 days 00:02:02.254512                 he   0.003799   \n",
       "42  0.873460  0 days 00:02:07.727737                 he   0.002781   \n",
       "43  0.836241  0 days 00:02:02.386805                 he   0.002223   \n",
       "44  0.746500  0 days 00:02:02.781243                 he   0.001351   \n",
       "45  0.778868  0 days 00:02:02.107878                 he   0.001427   \n",
       "46  0.824558  0 days 00:02:03.396844                 he   0.001977   \n",
       "47  0.861688  0 days 00:02:02.327933                 he   0.001671   \n",
       "48  0.727430  0 days 00:02:03.112748                 he   0.001345   \n",
       "49       NaN  0 days 00:01:59.470721       trunc_normal   0.000783   \n",
       "\n",
       "    params_momentum params_optimizer   params_scheduler params_scheduler_name  \\\n",
       "0          0.892873              SGD             StepLR                StepLR   \n",
       "1          0.910243              SGD      ExponentialLR                StepLR   \n",
       "2               NaN          RMSprop             StepLR     CosineAnnealingLR   \n",
       "3               NaN             Adam      ExponentialLR     CosineAnnealingLR   \n",
       "4               NaN             Adam      ExponentialLR     CosineAnnealingLR   \n",
       "5               NaN          RMSprop  CosineAnnealingLR         ExponentialLR   \n",
       "6          0.909065              SGD             StepLR         ExponentialLR   \n",
       "7               NaN             Adam             StepLR     CosineAnnealingLR   \n",
       "8          0.901259              SGD      ExponentialLR                StepLR   \n",
       "9               NaN             Adam      ExponentialLR                StepLR   \n",
       "10              NaN             Adam  CosineAnnealingLR                StepLR   \n",
       "11         0.989470              SGD             StepLR         ExponentialLR   \n",
       "12         0.987752              SGD      ExponentialLR         ExponentialLR   \n",
       "13              NaN             Adam             StepLR         ExponentialLR   \n",
       "14              NaN          RMSprop  CosineAnnealingLR         ExponentialLR   \n",
       "15         0.983258              SGD             StepLR                StepLR   \n",
       "16              NaN             Adam      ExponentialLR                StepLR   \n",
       "17         0.951815              SGD      ExponentialLR         ExponentialLR   \n",
       "18              NaN             Adam             StepLR                StepLR   \n",
       "19              NaN          RMSprop  CosineAnnealingLR         ExponentialLR   \n",
       "20         0.855895              SGD      ExponentialLR                StepLR   \n",
       "21         0.942698              SGD             StepLR         ExponentialLR   \n",
       "22         0.949152              SGD             StepLR         ExponentialLR   \n",
       "23         0.949549              SGD             StepLR         ExponentialLR   \n",
       "24         0.948067              SGD             StepLR         ExponentialLR   \n",
       "25         0.964365              SGD             StepLR         ExponentialLR   \n",
       "26         0.930871              SGD             StepLR         ExponentialLR   \n",
       "27         0.929150              SGD             StepLR         ExponentialLR   \n",
       "28         0.929102              SGD             StepLR         ExponentialLR   \n",
       "29         0.878635              SGD             StepLR         ExponentialLR   \n",
       "30         0.878018              SGD             StepLR         ExponentialLR   \n",
       "31         0.884040              SGD             StepLR         ExponentialLR   \n",
       "32         0.880970              SGD             StepLR         ExponentialLR   \n",
       "33         0.973165              SGD             StepLR         ExponentialLR   \n",
       "34         0.928068              SGD             StepLR         ExponentialLR   \n",
       "35         0.929322              SGD             StepLR         ExponentialLR   \n",
       "36         0.966672              SGD             StepLR         ExponentialLR   \n",
       "37         0.939569              SGD             StepLR     CosineAnnealingLR   \n",
       "38         0.921222              SGD             StepLR         ExponentialLR   \n",
       "39              NaN          RMSprop             StepLR         ExponentialLR   \n",
       "40         0.916119              SGD             StepLR     CosineAnnealingLR   \n",
       "41         0.879619              SGD  CosineAnnealingLR         ExponentialLR   \n",
       "42              NaN          RMSprop             StepLR     CosineAnnealingLR   \n",
       "43         0.923838              SGD             StepLR         ExponentialLR   \n",
       "44         0.938136              SGD             StepLR         ExponentialLR   \n",
       "45         0.935816              SGD             StepLR         ExponentialLR   \n",
       "46         0.917851              SGD             StepLR         ExponentialLR   \n",
       "47         0.959372              SGD             StepLR         ExponentialLR   \n",
       "48         0.897994              SGD             StepLR         ExponentialLR   \n",
       "49         0.895435              SGD  CosineAnnealingLR         ExponentialLR   \n",
       "\n",
       "       state  \n",
       "0   COMPLETE  \n",
       "1   COMPLETE  \n",
       "2   COMPLETE  \n",
       "3   COMPLETE  \n",
       "4   COMPLETE  \n",
       "5   COMPLETE  \n",
       "6   COMPLETE  \n",
       "7   COMPLETE  \n",
       "8   COMPLETE  \n",
       "9   COMPLETE  \n",
       "10  COMPLETE  \n",
       "11  COMPLETE  \n",
       "12  COMPLETE  \n",
       "13  COMPLETE  \n",
       "14  COMPLETE  \n",
       "15  COMPLETE  \n",
       "16  COMPLETE  \n",
       "17  COMPLETE  \n",
       "18  COMPLETE  \n",
       "19  COMPLETE  \n",
       "20  COMPLETE  \n",
       "21  COMPLETE  \n",
       "22  COMPLETE  \n",
       "23  COMPLETE  \n",
       "24  COMPLETE  \n",
       "25  COMPLETE  \n",
       "26  COMPLETE  \n",
       "27  COMPLETE  \n",
       "28  COMPLETE  \n",
       "29      FAIL  \n",
       "30      FAIL  \n",
       "31      FAIL  \n",
       "32  COMPLETE  \n",
       "33  COMPLETE  \n",
       "34  COMPLETE  \n",
       "35  COMPLETE  \n",
       "36  COMPLETE  \n",
       "37  COMPLETE  \n",
       "38  COMPLETE  \n",
       "39  COMPLETE  \n",
       "40  COMPLETE  \n",
       "41  COMPLETE  \n",
       "42  COMPLETE  \n",
       "43  COMPLETE  \n",
       "44  COMPLETE  \n",
       "45  COMPLETE  \n",
       "46  COMPLETE  \n",
       "47  COMPLETE  \n",
       "48  COMPLETE  \n",
       "49      FAIL  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
