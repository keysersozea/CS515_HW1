{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary torch and torchvision libraries\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import optuna\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.003494286840772853\n",
    "MOMENTUM = 0.9421216112061177\n",
    "SCHEDULAR_NAME = \"StepLR\"\n",
    "INIT_METHOD = \"kaiming_normal\"\n",
    "REG_METHOD = \"Data Augmentation + Weight Decay: 0.0005\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(MyCNN, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2), # output: 64 x 16 x 16\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2), # output: 128 x 8 x 8\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2), # output: 256 x 4 x 4\n",
    "\n",
    "            nn.Flatten(), \n",
    "            nn.Linear(256*4*4, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, num_classes))\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.network(x)\n",
    "        return x\n",
    "    \n",
    "    def init_weights(self):\n",
    "            for m in self.modules(): # self.modules() iterates through all modules (layers) in the model, including nested ones, allowing for operations like weight initialization to be applied universally.\n",
    "                if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "                    nn.init.kaiming_uniform_(m.weight, mode='fan_in', nonlinearity='relu')\n",
    "                    if m.bias is not None:\n",
    "                        nn.init.constant_(m.bias, 0)\n",
    "FinalModel = MyCNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model: torch.nn.Module,\n",
    "               data_loader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               accuracy,\n",
    "               device: torch.device = device):\n",
    "    \n",
    "    accuracy.reset()\n",
    "    train_loss, train_acc = 0, 0\n",
    "    model.to(device)\n",
    "    \n",
    "    for batch, (X, y) in enumerate(data_loader):\n",
    "        \n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        # Training\n",
    "        model.train()\n",
    "        # Forward pass\n",
    "        y_pred = model(X)\n",
    "        # Calculate loss per batch\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss # accumulate loss per batch\n",
    "        # Update accuracy\n",
    "        accuracy.update(y_pred, y)\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "    # Loss per epoch    \n",
    "    train_loss = train_loss / len(data_loader)\n",
    "    train_acc = accuracy.compute()\n",
    "    print(f\"Train loss: {train_loss:.5f} | Train accuracy: {train_acc*100:.2f}%\")\n",
    "    return train_loss, train_acc\n",
    "\n",
    "def test_step(model: torch.nn.Module,\n",
    "              data_loader: torch.utils.data.DataLoader,\n",
    "              loss_fn: torch.nn.Module,\n",
    "              accuracy,\n",
    "              device: torch.device = device):\n",
    "    \n",
    "    \n",
    "    accuracy.reset()\n",
    "    ## Testing\n",
    "    test_loss, test_acc = 0, 0\n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "    # Turn off gradients\n",
    "    with torch.inference_mode():\n",
    "        for X, y in data_loader:\n",
    "            # Move data to device\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            # Forward pass\n",
    "            test_pred = model(X)\n",
    "            # Calculate loss per batch\n",
    "            test_loss += loss_fn(test_pred, y)\n",
    "            # Update accuracy\n",
    "            accuracy.update(test_pred, y)\n",
    "    # Loss per epoch        \n",
    "    test_loss = test_loss / len(data_loader)\n",
    "    # Calculate accuracy\n",
    "    test_acc = accuracy.compute()\n",
    "    # Print loss and accuracy per epoch\n",
    "    print(f\"Test loss: {test_loss:.5f}, Test acc: {test_acc*100:.2f}%\\n\")\n",
    "    return test_loss, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "augmentation_transform = transforms.Compose([\n",
    "    #transforms.RandomResizedCrop(224),  # Crop images to 224x224\n",
    "    transforms.RandomHorizontalFlip(),  # Horizontally flip images with a 50% probability\n",
    "    transforms.RandomRotation(10),      # Randomly rotate images in the range (-10 degrees, 10 degrees)\n",
    "    transforms.ToTensor(),              # Convert images to PyTorch tensors\n",
    "])\n",
    "# Download and load the CIFAR-10 dataset\n",
    "train_data = CIFAR10(root='./data', \n",
    "                     train=True, \n",
    "                     download=True, \n",
    "                     transform=augmentation_transform)\n",
    "\n",
    "test_data = CIFAR10(root='./data',\n",
    "                                 train=False,\n",
    "                                 download=True,\n",
    "                                 transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data,\n",
    "                                           batch_size=32,\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_data,\n",
    "                                            batch_size=32,\n",
    "                                            shuffle=False)\n",
    "\n",
    "# See classes\n",
    "class_names = train_data.classes\n",
    "# Class to index\n",
    "cls_to_idx = train_data.class_to_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import accuracy metric\n",
    "from torchmetrics import Accuracy\n",
    "accuracy = Accuracy(task=\"multiclass\", num_classes=10).to(device)\n",
    "# Setup loss function and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(FinalModel.parameters(), lr=LR, momentum=MOMENTUM, weight_decay=0.0005)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "Train loss: 1.49068 | Train accuracy: 45.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 1/15 [00:32<07:35, 32.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.15696, Test acc: 58.46%\n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Train loss: 1.03306 | Train accuracy: 63.53%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 2/15 [01:05<07:02, 32.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.88544, Test acc: 68.84%\n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Train loss: 0.83941 | Train accuracy: 70.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 3/15 [01:36<06:27, 32.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.75444, Test acc: 73.91%\n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Train loss: 0.72638 | Train accuracy: 74.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 4/15 [02:08<05:53, 32.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.67379, Test acc: 76.56%\n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Train loss: 0.64509 | Train accuracy: 77.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 5/15 [02:40<05:20, 32.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.65063, Test acc: 77.75%\n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Train loss: 0.46087 | Train accuracy: 83.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 6/15 [03:13<04:50, 32.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.53755, Test acc: 81.66%\n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Train loss: 0.41730 | Train accuracy: 85.48%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 7/15 [03:45<04:17, 32.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.53623, Test acc: 82.10%\n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Train loss: 0.39137 | Train accuracy: 86.37%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 8/15 [04:18<03:46, 32.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.51402, Test acc: 82.49%\n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Train loss: 0.36272 | Train accuracy: 87.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 9/15 [04:51<03:15, 32.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.49835, Test acc: 83.03%\n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Train loss: 0.33854 | Train accuracy: 88.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 10/15 [05:26<02:46, 33.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.52027, Test acc: 82.84%\n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Train loss: 0.27882 | Train accuracy: 90.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 11/15 [06:01<02:15, 33.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.49701, Test acc: 83.78%\n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Train loss: 0.26466 | Train accuracy: 90.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 12/15 [06:34<01:40, 33.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.50026, Test acc: 84.00%\n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Train loss: 0.25689 | Train accuracy: 91.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 13/15 [07:07<01:07, 33.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.50513, Test acc: 83.94%\n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Train loss: 0.24812 | Train accuracy: 91.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 14/15 [07:42<00:33, 33.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.50433, Test acc: 84.02%\n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Train loss: 0.23920 | Train accuracy: 91.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [08:14<00:00, 32.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.50683, Test acc: 83.74%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Using tqdm for progress bar\n",
    "from tqdm.auto import tqdm\n",
    "torch.manual_seed(42)\n",
    "\n",
    "epochs = 15\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
    "    train_loss, train_acc = train_step(FinalModel, train_loader, loss_fn, optimizer, accuracy)\n",
    "    test_loss, test_acc = test_step(FinalModel, test_loader, loss_fn, accuracy)\n",
    "    scheduler.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
