{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install optuna\n# Import necessary torch and torchvision libraries\nimport torch\nimport torchvision\nimport torchvision.transforms as transforms\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision.datasets import CIFAR10\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport optuna\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2024-03-22T22:34:30.931557Z","iopub.execute_input":"2024-03-22T22:34:30.931963Z","iopub.status.idle":"2024-03-22T22:34:42.888390Z","shell.execute_reply.started":"2024-03-22T22:34:30.931931Z","shell.execute_reply":"2024-03-22T22:34:42.887376Z"},"trusted":true},"execution_count":135,"outputs":[{"name":"stdout","text":"Requirement already satisfied: optuna in /opt/conda/lib/python3.10/site-packages (3.6.0)\nRequirement already satisfied: alembic>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from optuna) (1.13.1)\nRequirement already satisfied: colorlog in /opt/conda/lib/python3.10/site-packages (from optuna) (6.8.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from optuna) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from optuna) (21.3)\nRequirement already satisfied: sqlalchemy>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from optuna) (2.0.25)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from optuna) (4.66.1)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from optuna) (6.0.1)\nRequirement already satisfied: Mako in /opt/conda/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (1.3.2)\nRequirement already satisfied: typing-extensions>=4 in /opt/conda/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->optuna) (3.1.1)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\nRequirement already satisfied: MarkupSafe>=0.9.2 in /opt/conda/lib/python3.10/site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.3)\n","output_type":"stream"}]},{"cell_type":"code","source":"##### Best Hyperparameters #####\n#LR = 0.001852\nLR = 0.003494286840772853\n#MOMENTUM = 0.870915\nMOMENTUM = 0.9421216112061177\nSCHEDULAR_NAME = \"StepLR\"\nINIT_METHOD = \"kaiming_normal\"","metadata":{"execution":{"iopub.status.busy":"2024-03-22T22:34:42.890896Z","iopub.execute_input":"2024-03-22T22:34:42.891206Z","iopub.status.idle":"2024-03-22T22:34:42.896139Z","shell.execute_reply.started":"2024-03-22T22:34:42.891174Z","shell.execute_reply":"2024-03-22T22:34:42.895193Z"},"trusted":true},"execution_count":136,"outputs":[]},{"cell_type":"code","source":"class MyCNN(nn.Module):\n    def __init__(self, num_classes=10):\n        super(MyCNN, self).__init__()\n        self.network = nn.Sequential(\n            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2), # output: 64 x 16 x 16\n\n            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2), # output: 128 x 8 x 8\n\n            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2), # output: 256 x 4 x 4\n\n            nn.Flatten(), \n            nn.Linear(256*4*4, 1024),\n            nn.ReLU(),\n            nn.Linear(1024, 512),\n            nn.ReLU(),\n            nn.Linear(512, num_classes))\n        self.init_weights()\n\n    def forward(self, x):\n        x = self.network(x)\n        return x\n    \n    def init_weights(self):\n            for m in self.modules(): # self.modules() iterates through all modules (layers) in the model, including nested ones, allowing for operations like weight initialization to be applied universally.\n                if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n                    nn.init.kaiming_uniform_(m.weight, mode='fan_in', nonlinearity='relu')\n                    if m.bias is not None:\n                        nn.init.constant_(m.bias, 0)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-22T22:34:42.897229Z","iopub.execute_input":"2024-03-22T22:34:42.897473Z","iopub.status.idle":"2024-03-22T22:34:42.912243Z","shell.execute_reply.started":"2024-03-22T22:34:42.897451Z","shell.execute_reply":"2024-03-22T22:34:42.911341Z"},"trusted":true},"execution_count":137,"outputs":[]},{"cell_type":"code","source":"def train_step(model: torch.nn.Module,\n               data_loader: torch.utils.data.DataLoader,\n               loss_fn: torch.nn.Module,\n               optimizer: torch.optim.Optimizer,\n               accuracy,\n               device: torch.device = device):\n    \n    accuracy.reset()\n    train_loss, train_acc = 0, 0\n    model.to(device)\n    \n    for batch, (X, y) in enumerate(data_loader):\n        \n        X = X.to(device)\n        y = y.to(device)\n        \n        # Training\n        model.train()\n        # Forward pass\n        y_pred = model(X)\n        # Calculate loss per batch\n        loss = loss_fn(y_pred, y)\n        train_loss += loss # accumulate loss per batch\n        # Update accuracy\n        accuracy.update(y_pred, y)\n        # Zero the gradients\n        optimizer.zero_grad()\n        # Backward pass\n        loss.backward()\n        # Update weights\n        optimizer.step()\n    # Loss per epoch    \n    train_loss = train_loss / len(data_loader)\n    train_acc = accuracy.compute()\n    print(f\"Train loss: {train_loss:.5f} | Train accuracy: {train_acc*100:.2f}%\")\n    return train_loss, train_acc\n\ndef test_step(model: torch.nn.Module,\n              data_loader: torch.utils.data.DataLoader,\n              loss_fn: torch.nn.Module,\n              accuracy,\n              device: torch.device = device):\n    \n    \n    accuracy.reset()\n    ## Testing\n    test_loss, test_acc = 0, 0\n    # Set model to evaluation mode\n    model.eval()\n    # Turn off gradients\n    with torch.inference_mode():\n        for X, y in data_loader:\n            # Move data to device\n            X = X.to(device)\n            y = y.to(device)\n            # Forward pass\n            test_pred = model(X)\n            # Calculate loss per batch\n            test_loss += loss_fn(test_pred, y)\n            # Update accuracy\n            accuracy.update(test_pred, y)\n    # Loss per epoch        \n    test_loss = test_loss / len(data_loader)\n    # Calculate accuracy\n    test_acc = accuracy.compute()\n    # Print loss and accuracy per epoch\n    print(f\"Test loss: {test_loss:.5f}, Test acc: {test_acc*100:.2f}%\\n\")\n    return test_loss, test_acc","metadata":{"execution":{"iopub.status.busy":"2024-03-22T22:34:42.913516Z","iopub.execute_input":"2024-03-22T22:34:42.913870Z","iopub.status.idle":"2024-03-22T22:34:42.928418Z","shell.execute_reply.started":"2024-03-22T22:34:42.913839Z","shell.execute_reply":"2024-03-22T22:34:42.927641Z"},"trusted":true},"execution_count":138,"outputs":[]},{"cell_type":"markdown","source":"# Data Augmentation","metadata":{}},{"cell_type":"code","source":"augmentation_transform = transforms.Compose([\n    #transforms.RandomResizedCrop(224),  # Crop images to 224x224\n    transforms.RandomHorizontalFlip(),  # Horizontally flip images with a 50% probability\n    transforms.RandomRotation(10),      # Randomly rotate images in the range (-10 degrees, 10 degrees)\n    transforms.ToTensor(),              # Convert images to PyTorch tensors\n])\n# Download and load the CIFAR-10 dataset\ntrain_data = CIFAR10(root='./data', \n                     train=True, \n                     download=True, \n                     transform=transforms.ToTensor())\n\ntest_data = CIFAR10(root='./data',\n                    train=False,\n                    download=True,\n                    transform=transforms.ToTensor())\n\naugmented_train_data = CIFAR10(root='./data',\n                                train=True,\n                                transform=augmentation_transform)\naugmented_test_data = CIFAR10(root='./data',\n                                 train=False,\n                                 transform=augmentation_transform)\n\n# See classes\nclass_names = train_data.classes\n# Class to index\ncls_to_idx = train_data.class_to_idx\n\n# Create a DataLoader object to load data in batches\nno_augmentation_train_loader = torch.utils.data.DataLoader(dataset=train_data,\n                                           batch_size=32,\n                                           shuffle=True)\nno_augmentation_test_loader = torch.utils.data.DataLoader(dataset=test_data,\n                                            batch_size=32,\n                                            shuffle=False)\n\naugmented_train_loader = torch.utils.data.DataLoader(dataset=augmented_train_data,\n                                           batch_size=32,\n                                           shuffle=True)\naugmented_test_loader = torch.utils.data.DataLoader(dataset=augmented_train_data,\n                                            batch_size=32,\n                                            shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-03-22T22:34:42.930856Z","iopub.execute_input":"2024-03-22T22:34:42.931114Z","iopub.status.idle":"2024-03-22T22:34:45.459857Z","shell.execute_reply.started":"2024-03-22T22:34:42.931092Z","shell.execute_reply":"2024-03-22T22:34:45.458832Z"},"trusted":true},"execution_count":139,"outputs":[{"name":"stdout","text":"Files already downloaded and verified\nFiles already downloaded and verified\n","output_type":"stream"}]},{"cell_type":"code","source":"# Import accuracy metric\nfrom torchmetrics import Accuracy\naccuracy = Accuracy(task=\"multiclass\", num_classes=10).to(device)\n# Setup loss function and optimizer\nloss_fn = nn.CrossEntropyLoss()\n","metadata":{"execution":{"iopub.status.busy":"2024-03-22T22:34:45.461059Z","iopub.execute_input":"2024-03-22T22:34:45.461356Z","iopub.status.idle":"2024-03-22T22:34:45.468968Z","shell.execute_reply.started":"2024-03-22T22:34:45.461330Z","shell.execute_reply":"2024-03-22T22:34:45.468055Z"},"trusted":true},"execution_count":140,"outputs":[]},{"cell_type":"code","source":"def objective(trial):\n    \n    model = MyCNN()\n\n    reg_method = trial.suggest_categorical('reg_method', [\"No_Regularization\", \"Weight Decay: 0.0005\", \"Weight Decay: 0.0001\",\n                                                         \"Data Augmentation\", 'Data Augmentation - WD: 0.0001', 'Data Augmentation - WD: 0.0005'])\n        \n    if reg_method == \"Weight Decay: 0.0005\":\n        train_loader = no_augmentation_train_loader\n        test_loader = no_augmentation_test_loader\n        optimizer = optim.SGD(model.parameters(), lr=LR, momentum=MOMENTUM, weight_decay=0.0005)\n    elif reg_method == \"Weight Decay: 0.0001\":\n        train_loader = no_augmentation_train_loader\n        test_loader = no_augmentation_test_loader\n        optimizer = optim.SGD(model.parameters(), lr=LR, momentum=MOMENTUM, weight_decay=0.0001)\n    elif reg_method == \"Data Augmentation\":\n        train_loader = augmented_train_loader\n        test_loader = no_augmentation_test_loader\n        optimizer = optim.SGD(model.parameters(), lr=LR, momentum=MOMENTUM)\n    elif reg_method == \"Data Augmentation - WD: 0.0001\":\n        train_loader = augmented_train_loader\n        test_loader = no_augmentation_test_loader\n        optimizer = optim.SGD(model.parameters(), lr=LR, momentum=MOMENTUM, weight_decay=0.0001)\n    elif reg_method == \"Data Augmentation - WD: 0.0005\":\n        train_loader = augmented_train_loader\n        test_loader = no_augmentation_test_loader\n        optimizer = optim.SGD(model.parameters(), lr=LR, momentum=MOMENTUM, weight_decay=0.0005)\n    elif reg_method == \"No_Regularization\":\n        train_loader = no_augmentation_train_loader\n        test_loader = no_augmentation_test_loader\n        optimizer = optim.SGD(model.parameters(), lr=LR, momentum=MOMENTUM)\n    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.2)\n    \n    epochs = 15\n    \n    for epoch in range(epochs):\n        print(f\"Epoch {epoch+1}\\n-------------------------------\")\n        train_loss, train_acc = train_step(model, train_loader, loss_fn, optimizer, accuracy)\n        test_loss, test_acc = test_step(model, test_loader, loss_fn, accuracy)\n        scheduler.step()\n    return test_acc\n\nsearch_space = {\n    'reg_method': ['No_Regularization', 'Weight Decay: 0.0001', 'Weight Decay: 0.0005', 'Data Augmentation',\n                  'Data Augmentation - WD: 0.0001', 'Data Augmentation - WD: 0.0005']\n}\nstudy_augmentation = optuna.create_study(direction='maximize',\n                                         sampler=optuna.samplers.GridSampler(search_space))\nstudy_augmentation.optimize(objective, n_trials=6)\n\nprint('Best trial:')\ntrial_augmentation = study_augmentation.best_trial\n\nprint(f'Value: {trial_augmentation.value}')\nprint('Params: ')\nfor key, value in trial_augmentation.params.items():\n    print(f'{key}: {value}')","metadata":{"execution":{"iopub.status.busy":"2024-03-22T22:34:45.470198Z","iopub.execute_input":"2024-03-22T22:34:45.470475Z","iopub.status.idle":"2024-03-22T23:01:07.620695Z","shell.execute_reply.started":"2024-03-22T22:34:45.470441Z","shell.execute_reply":"2024-03-22T23:01:07.619709Z"},"trusted":true},"execution_count":141,"outputs":[{"name":"stderr","text":"[I 2024-03-22 22:34:45,483] A new study created in memory with name: no-name-2c1c469c-14f8-4f44-b6db-4c59b645b469\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1\n-------------------------------\nTrain loss: 1.55512 | Train accuracy: 43.23%\nTest loss: 1.25762, Test acc: 53.97%\n\nEpoch 2\n-------------------------------\nTrain loss: 1.05975 | Train accuracy: 62.21%\nTest loss: 0.93838, Test acc: 67.01%\n\nEpoch 3\n-------------------------------\nTrain loss: 0.86162 | Train accuracy: 69.79%\nTest loss: 0.79813, Test acc: 72.58%\n\nEpoch 4\n-------------------------------\nTrain loss: 0.73851 | Train accuracy: 74.37%\nTest loss: 0.70851, Test acc: 75.88%\n\nEpoch 5\n-------------------------------\nTrain loss: 0.65195 | Train accuracy: 77.25%\nTest loss: 0.65388, Test acc: 77.55%\n\nEpoch 6\n-------------------------------\nTrain loss: 0.46789 | Train accuracy: 83.76%\nTest loss: 0.53937, Test acc: 81.58%\n\nEpoch 7\n-------------------------------\nTrain loss: 0.41625 | Train accuracy: 85.64%\nTest loss: 0.54360, Test acc: 82.03%\n\nEpoch 8\n-------------------------------\nTrain loss: 0.38566 | Train accuracy: 86.40%\nTest loss: 0.53733, Test acc: 82.42%\n\nEpoch 9\n-------------------------------\nTrain loss: 0.35778 | Train accuracy: 87.42%\nTest loss: 0.54115, Test acc: 81.79%\n\nEpoch 10\n-------------------------------\nTrain loss: 0.33102 | Train accuracy: 88.35%\nTest loss: 0.53949, Test acc: 82.97%\n\nEpoch 11\n-------------------------------\nTrain loss: 0.27782 | Train accuracy: 90.50%\nTest loss: 0.53147, Test acc: 83.59%\n\nEpoch 12\n-------------------------------\nTrain loss: 0.26318 | Train accuracy: 91.06%\nTest loss: 0.53243, Test acc: 83.84%\n\nEpoch 13\n-------------------------------\nTrain loss: 0.25057 | Train accuracy: 91.47%\nTest loss: 0.53712, Test acc: 83.67%\n\nEpoch 14\n-------------------------------\nTrain loss: 0.24251 | Train accuracy: 91.75%\nTest loss: 0.54170, Test acc: 83.59%\n\nEpoch 15\n-------------------------------\nTrain loss: 0.23691 | Train accuracy: 91.84%\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-03-22 22:39:59,257] Trial 0 finished with value: 0.8357999920845032 and parameters: {'reg_method': 'Data Augmentation'}. Best is trial 0 with value: 0.8357999920845032.\n","output_type":"stream"},{"name":"stdout","text":"Test loss: 0.54855, Test acc: 83.58%\n\nEpoch 1\n-------------------------------\nTrain loss: 1.54364 | Train accuracy: 43.66%\nTest loss: 1.19505, Test acc: 57.56%\n\nEpoch 2\n-------------------------------\nTrain loss: 1.05487 | Train accuracy: 62.76%\nTest loss: 0.88273, Test acc: 69.14%\n\nEpoch 3\n-------------------------------\nTrain loss: 0.84807 | Train accuracy: 70.25%\nTest loss: 0.85398, Test acc: 69.99%\n\nEpoch 4\n-------------------------------\nTrain loss: 0.72865 | Train accuracy: 74.62%\nTest loss: 0.70056, Test acc: 75.59%\n\nEpoch 5\n-------------------------------\nTrain loss: 0.64601 | Train accuracy: 77.38%\nTest loss: 0.65774, Test acc: 77.64%\n\nEpoch 6\n-------------------------------\nTrain loss: 0.45529 | Train accuracy: 84.19%\nTest loss: 0.55310, Test acc: 81.66%\n\nEpoch 7\n-------------------------------\nTrain loss: 0.41242 | Train accuracy: 85.61%\nTest loss: 0.53517, Test acc: 81.95%\n\nEpoch 8\n-------------------------------\nTrain loss: 0.37494 | Train accuracy: 86.91%\nTest loss: 0.53192, Test acc: 82.48%\n\nEpoch 9\n-------------------------------\nTrain loss: 0.35297 | Train accuracy: 87.72%\nTest loss: 0.54338, Test acc: 82.56%\n\nEpoch 10\n-------------------------------\nTrain loss: 0.32418 | Train accuracy: 88.71%\nTest loss: 0.54137, Test acc: 82.61%\n\nEpoch 11\n-------------------------------\nTrain loss: 0.26963 | Train accuracy: 90.80%\nTest loss: 0.52628, Test acc: 83.37%\n\nEpoch 12\n-------------------------------\nTrain loss: 0.25260 | Train accuracy: 91.28%\nTest loss: 0.53426, Test acc: 83.37%\n\nEpoch 13\n-------------------------------\nTrain loss: 0.24193 | Train accuracy: 91.75%\nTest loss: 0.53186, Test acc: 83.56%\n\nEpoch 14\n-------------------------------\nTrain loss: 0.23645 | Train accuracy: 91.94%\nTest loss: 0.54212, Test acc: 83.44%\n\nEpoch 15\n-------------------------------\nTrain loss: 0.22776 | Train accuracy: 92.27%\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-03-22 22:45:14,654] Trial 1 finished with value: 0.833299994468689 and parameters: {'reg_method': 'Data Augmentation - WD: 0.0001'}. Best is trial 0 with value: 0.8357999920845032.\n","output_type":"stream"},{"name":"stdout","text":"Test loss: 0.54522, Test acc: 83.33%\n\nEpoch 1\n-------------------------------\nTrain loss: 1.44081 | Train accuracy: 47.53%\nTest loss: 1.05845, Test acc: 62.31%\n\nEpoch 2\n-------------------------------\nTrain loss: 0.92491 | Train accuracy: 67.51%\nTest loss: 0.84129, Test acc: 70.47%\n\nEpoch 3\n-------------------------------\nTrain loss: 0.69769 | Train accuracy: 75.51%\nTest loss: 0.73222, Test acc: 74.71%\n\nEpoch 4\n-------------------------------\nTrain loss: 0.54559 | Train accuracy: 80.94%\nTest loss: 0.68618, Test acc: 77.50%\n\nEpoch 5\n-------------------------------\nTrain loss: 0.42096 | Train accuracy: 85.30%\nTest loss: 0.66540, Test acc: 77.97%\n\nEpoch 6\n-------------------------------\nTrain loss: 0.14576 | Train accuracy: 95.11%\nTest loss: 0.67320, Test acc: 81.07%\n\nEpoch 7\n-------------------------------\nTrain loss: 0.05846 | Train accuracy: 98.23%\nTest loss: 0.82891, Test acc: 80.84%\n\nEpoch 8\n-------------------------------\nTrain loss: 0.01860 | Train accuracy: 99.67%\nTest loss: 1.04424, Test acc: 80.91%\n\nEpoch 9\n-------------------------------\nTrain loss: 0.00500 | Train accuracy: 99.97%\nTest loss: 1.20623, Test acc: 81.08%\n\nEpoch 10\n-------------------------------\nTrain loss: 0.00190 | Train accuracy: 100.00%\nTest loss: 1.32245, Test acc: 81.12%\n\nEpoch 11\n-------------------------------\nTrain loss: 0.00111 | Train accuracy: 100.00%\nTest loss: 1.33752, Test acc: 81.03%\n\nEpoch 12\n-------------------------------\nTrain loss: 0.00102 | Train accuracy: 100.00%\nTest loss: 1.35479, Test acc: 80.98%\n\nEpoch 13\n-------------------------------\nTrain loss: 0.00096 | Train accuracy: 100.00%\nTest loss: 1.36842, Test acc: 81.01%\n\nEpoch 14\n-------------------------------\nTrain loss: 0.00091 | Train accuracy: 100.00%\nTest loss: 1.38149, Test acc: 81.00%\n\nEpoch 15\n-------------------------------\nTrain loss: 0.00086 | Train accuracy: 100.00%\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-03-22 22:48:47,657] Trial 2 finished with value: 0.8101000189781189 and parameters: {'reg_method': 'Weight Decay: 0.0001'}. Best is trial 0 with value: 0.8357999920845032.\n","output_type":"stream"},{"name":"stdout","text":"Test loss: 1.39326, Test acc: 81.01%\n\nEpoch 1\n-------------------------------\nTrain loss: 1.49244 | Train accuracy: 45.54%\nTest loss: 1.18819, Test acc: 58.28%\n\nEpoch 2\n-------------------------------\nTrain loss: 0.94994 | Train accuracy: 66.56%\nTest loss: 0.89372, Test acc: 68.40%\n\nEpoch 3\n-------------------------------\nTrain loss: 0.72643 | Train accuracy: 74.88%\nTest loss: 0.78613, Test acc: 72.93%\n\nEpoch 4\n-------------------------------\nTrain loss: 0.57334 | Train accuracy: 80.11%\nTest loss: 0.66350, Test acc: 77.29%\n\nEpoch 5\n-------------------------------\nTrain loss: 0.44945 | Train accuracy: 84.26%\nTest loss: 0.67602, Test acc: 77.65%\n\nEpoch 6\n-------------------------------\nTrain loss: 0.17216 | Train accuracy: 94.22%\nTest loss: 0.65002, Test acc: 81.36%\n\nEpoch 7\n-------------------------------\nTrain loss: 0.08251 | Train accuracy: 97.41%\nTest loss: 0.76311, Test acc: 81.50%\n\nEpoch 8\n-------------------------------\nTrain loss: 0.03489 | Train accuracy: 99.15%\nTest loss: 0.88506, Test acc: 81.12%\n\nEpoch 9\n-------------------------------\nTrain loss: 0.01218 | Train accuracy: 99.83%\nTest loss: 1.03031, Test acc: 81.26%\n\nEpoch 10\n-------------------------------\nTrain loss: 0.00420 | Train accuracy: 99.98%\nTest loss: 1.16280, Test acc: 81.42%\n\nEpoch 11\n-------------------------------\nTrain loss: 0.00210 | Train accuracy: 100.00%\nTest loss: 1.17271, Test acc: 81.51%\n\nEpoch 12\n-------------------------------\nTrain loss: 0.00184 | Train accuracy: 100.00%\nTest loss: 1.18652, Test acc: 81.35%\n\nEpoch 13\n-------------------------------\nTrain loss: 0.00172 | Train accuracy: 100.00%\nTest loss: 1.19840, Test acc: 81.44%\n\nEpoch 14\n-------------------------------\nTrain loss: 0.00165 | Train accuracy: 100.00%\nTest loss: 1.20753, Test acc: 81.37%\n\nEpoch 15\n-------------------------------\nTrain loss: 0.00159 | Train accuracy: 100.00%\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-03-22 22:52:20,641] Trial 3 finished with value: 0.8138999938964844 and parameters: {'reg_method': 'Weight Decay: 0.0005'}. Best is trial 0 with value: 0.8357999920845032.\n","output_type":"stream"},{"name":"stdout","text":"Test loss: 1.21580, Test acc: 81.39%\n\nEpoch 1\n-------------------------------\nTrain loss: 1.58794 | Train accuracy: 41.86%\nTest loss: 1.16154, Test acc: 58.41%\n\nEpoch 2\n-------------------------------\nTrain loss: 1.07811 | Train accuracy: 61.67%\nTest loss: 0.94549, Test acc: 66.96%\n\nEpoch 3\n-------------------------------\nTrain loss: 0.87095 | Train accuracy: 69.30%\nTest loss: 0.79401, Test acc: 72.50%\n\nEpoch 4\n-------------------------------\nTrain loss: 0.74672 | Train accuracy: 73.94%\nTest loss: 0.75230, Test acc: 74.42%\n\nEpoch 5\n-------------------------------\nTrain loss: 0.66344 | Train accuracy: 76.91%\nTest loss: 0.67443, Test acc: 77.11%\n\nEpoch 6\n-------------------------------\nTrain loss: 0.47476 | Train accuracy: 83.42%\nTest loss: 0.56208, Test acc: 81.43%\n\nEpoch 7\n-------------------------------\nTrain loss: 0.42816 | Train accuracy: 85.09%\nTest loss: 0.54171, Test acc: 82.09%\n\nEpoch 8\n-------------------------------\nTrain loss: 0.39882 | Train accuracy: 86.28%\nTest loss: 0.52832, Test acc: 82.15%\n\nEpoch 9\n-------------------------------\nTrain loss: 0.37006 | Train accuracy: 87.00%\nTest loss: 0.53618, Test acc: 82.22%\n\nEpoch 10\n-------------------------------\nTrain loss: 0.34897 | Train accuracy: 87.83%\nTest loss: 0.51328, Test acc: 83.21%\n\nEpoch 11\n-------------------------------\nTrain loss: 0.28849 | Train accuracy: 90.25%\nTest loss: 0.50943, Test acc: 83.89%\n\nEpoch 12\n-------------------------------\nTrain loss: 0.27527 | Train accuracy: 90.58%\nTest loss: 0.50953, Test acc: 84.10%\n\nEpoch 13\n-------------------------------\nTrain loss: 0.26217 | Train accuracy: 91.05%\nTest loss: 0.51550, Test acc: 83.94%\n\nEpoch 14\n-------------------------------\nTrain loss: 0.25411 | Train accuracy: 91.24%\nTest loss: 0.52287, Test acc: 83.98%\n\nEpoch 15\n-------------------------------\nTrain loss: 0.24353 | Train accuracy: 91.66%\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-03-22 22:57:36,577] Trial 4 finished with value: 0.8378999829292297 and parameters: {'reg_method': 'Data Augmentation - WD: 0.0005'}. Best is trial 4 with value: 0.8378999829292297.\n","output_type":"stream"},{"name":"stdout","text":"Test loss: 0.52361, Test acc: 83.79%\n\nEpoch 1\n-------------------------------\nTrain loss: 1.43381 | Train accuracy: 47.74%\nTest loss: 1.09948, Test acc: 60.67%\n\nEpoch 2\n-------------------------------\nTrain loss: 0.92825 | Train accuracy: 67.11%\nTest loss: 0.88050, Test acc: 69.24%\n\nEpoch 3\n-------------------------------\nTrain loss: 0.69776 | Train accuracy: 75.53%\nTest loss: 0.71249, Test acc: 75.68%\n\nEpoch 4\n-------------------------------\nTrain loss: 0.55450 | Train accuracy: 80.67%\nTest loss: 0.66122, Test acc: 77.66%\n\nEpoch 5\n-------------------------------\nTrain loss: 0.42038 | Train accuracy: 85.32%\nTest loss: 0.67116, Test acc: 77.76%\n\nEpoch 6\n-------------------------------\nTrain loss: 0.14310 | Train accuracy: 95.28%\nTest loss: 0.74441, Test acc: 80.21%\n\nEpoch 7\n-------------------------------\nTrain loss: 0.05187 | Train accuracy: 98.54%\nTest loss: 0.90424, Test acc: 80.13%\n\nEpoch 8\n-------------------------------\nTrain loss: 0.01478 | Train accuracy: 99.75%\nTest loss: 1.16120, Test acc: 80.05%\n\nEpoch 9\n-------------------------------\nTrain loss: 0.00374 | Train accuracy: 99.98%\nTest loss: 1.31863, Test acc: 80.44%\n\nEpoch 10\n-------------------------------\nTrain loss: 0.00145 | Train accuracy: 100.00%\nTest loss: 1.44047, Test acc: 80.53%\n\nEpoch 11\n-------------------------------\nTrain loss: 0.00087 | Train accuracy: 100.00%\nTest loss: 1.46092, Test acc: 80.55%\n\nEpoch 12\n-------------------------------\nTrain loss: 0.00080 | Train accuracy: 100.00%\nTest loss: 1.47900, Test acc: 80.51%\n\nEpoch 13\n-------------------------------\nTrain loss: 0.00075 | Train accuracy: 100.00%\nTest loss: 1.49507, Test acc: 80.48%\n\nEpoch 14\n-------------------------------\nTrain loss: 0.00070 | Train accuracy: 100.00%\nTest loss: 1.51035, Test acc: 80.50%\n\nEpoch 15\n-------------------------------\nTrain loss: 0.00066 | Train accuracy: 100.00%\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-03-22 23:01:07,615] Trial 5 finished with value: 0.8043000102043152 and parameters: {'reg_method': 'No_Regularization'}. Best is trial 4 with value: 0.8378999829292297.\n","output_type":"stream"},{"name":"stdout","text":"Test loss: 1.52378, Test acc: 80.43%\n\nBest trial:\nValue: 0.8378999829292297\nParams: \nreg_method: Data Augmentation - WD: 0.0005\n","output_type":"stream"}]},{"cell_type":"code","source":"optuna.visualization.plot_optimization_history(study_augmentation)","metadata":{"execution":{"iopub.status.busy":"2024-03-22T23:04:15.119222Z","iopub.execute_input":"2024-03-22T23:04:15.119925Z","iopub.status.idle":"2024-03-22T23:04:15.132687Z","shell.execute_reply.started":"2024-03-22T23:04:15.119890Z","shell.execute_reply":"2024-03-22T23:04:15.131865Z"},"trusted":true},"execution_count":155,"outputs":[{"output_type":"display_data","data":{"text/html":"<div>                            <div id=\"9cb6ed47-63a3-41e3-aaa5-0ac4989b3bd3\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"9cb6ed47-63a3-41e3-aaa5-0ac4989b3bd3\")) {                    Plotly.newPlot(                        \"9cb6ed47-63a3-41e3-aaa5-0ac4989b3bd3\",                        [{\"mode\":\"markers\",\"name\":\"Objective Value\",\"x\":[0,1,2,3,4,5],\"y\":[0.8357999920845032,0.833299994468689,0.8101000189781189,0.8138999938964844,0.8378999829292297,0.8043000102043152],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Best Value\",\"x\":[0,1,2,3,4,5],\"y\":[0.8357999920845032,0.8357999920845032,0.8357999920845032,0.8357999920845032,0.8378999829292297,0.8378999829292297],\"type\":\"scatter\"},{\"marker\":{\"color\":\"#cccccc\"},\"mode\":\"markers\",\"name\":\"Infeasible Trial\",\"showlegend\":false,\"x\":[],\"y\":[],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"Optimization History Plot\"},\"xaxis\":{\"title\":{\"text\":\"Trial\"}},\"yaxis\":{\"title\":{\"text\":\"Objective Value\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('9cb6ed47-63a3-41e3-aaa5-0ac4989b3bd3');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                });            </script>        </div>"},"metadata":{}}]},{"cell_type":"code","source":"df = study_augmentation.trials_dataframe()\n\n# Set dataframe column width option\npd.set_option('display.max_colwidth', None)\n\nprint(df)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-22T23:02:39.998949Z","iopub.execute_input":"2024-03-22T23:02:39.999816Z","iopub.status.idle":"2024-03-22T23:02:40.014398Z","shell.execute_reply.started":"2024-03-22T23:02:39.999785Z","shell.execute_reply":"2024-03-22T23:02:40.013039Z"},"trusted":true},"execution_count":152,"outputs":[{"name":"stdout","text":"   number   value             datetime_start          datetime_complete  \\\n0       0  0.8358 2024-03-22 22:34:45.484816 2024-03-22 22:39:59.257620   \n1       1  0.8333 2024-03-22 22:39:59.259245 2024-03-22 22:45:14.654607   \n2       2  0.8101 2024-03-22 22:45:14.656133 2024-03-22 22:48:47.656748   \n3       3  0.8139 2024-03-22 22:48:47.658216 2024-03-22 22:52:20.641499   \n4       4  0.8379 2024-03-22 22:52:20.643028 2024-03-22 22:57:36.577275   \n5       5  0.8043 2024-03-22 22:57:36.578889 2024-03-22 23:01:07.614869   \n\n                duration               params_reg_method  \\\n0 0 days 00:05:13.772804               Data Augmentation   \n1 0 days 00:05:15.395362  Data Augmentation - WD: 0.0001   \n2 0 days 00:03:33.000615            Weight Decay: 0.0001   \n3 0 days 00:03:32.983283            Weight Decay: 0.0005   \n4 0 days 00:05:15.934247  Data Augmentation - WD: 0.0005   \n5 0 days 00:03:31.035980               No_Regularization   \n\n   system_attrs_grid_id  \\\n0                     0   \n1                     1   \n2                     2   \n3                     3   \n4                     4   \n5                     5   \n\n                                                                                                                                                        system_attrs_search_space  \\\n0  {'reg_method': ['No_Regularization', 'Weight Decay: 0.0001', 'Weight Decay: 0.0005', 'Data Augmentation', 'Data Augmentation - WD: 0.0001', 'Data Augmentation - WD: 0.0005']}   \n1  {'reg_method': ['No_Regularization', 'Weight Decay: 0.0001', 'Weight Decay: 0.0005', 'Data Augmentation', 'Data Augmentation - WD: 0.0001', 'Data Augmentation - WD: 0.0005']}   \n2  {'reg_method': ['No_Regularization', 'Weight Decay: 0.0001', 'Weight Decay: 0.0005', 'Data Augmentation', 'Data Augmentation - WD: 0.0001', 'Data Augmentation - WD: 0.0005']}   \n3  {'reg_method': ['No_Regularization', 'Weight Decay: 0.0001', 'Weight Decay: 0.0005', 'Data Augmentation', 'Data Augmentation - WD: 0.0001', 'Data Augmentation - WD: 0.0005']}   \n4  {'reg_method': ['No_Regularization', 'Weight Decay: 0.0001', 'Weight Decay: 0.0005', 'Data Augmentation', 'Data Augmentation - WD: 0.0001', 'Data Augmentation - WD: 0.0005']}   \n5  {'reg_method': ['No_Regularization', 'Weight Decay: 0.0001', 'Weight Decay: 0.0005', 'Data Augmentation', 'Data Augmentation - WD: 0.0001', 'Data Augmentation - WD: 0.0005']}   \n\n      state  \n0  COMPLETE  \n1  COMPLETE  \n2  COMPLETE  \n3  COMPLETE  \n4  COMPLETE  \n5  COMPLETE  \n","output_type":"stream"}]},{"cell_type":"code","source":"#df.drop(columns=['datetime_complete'], inplace=True)\ndf.to_csv('regularization_comparison.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-03-22T23:08:41.954376Z","iopub.execute_input":"2024-03-22T23:08:41.955136Z","iopub.status.idle":"2024-03-22T23:08:41.961318Z","shell.execute_reply.started":"2024-03-22T23:08:41.955103Z","shell.execute_reply":"2024-03-22T23:08:41.960424Z"},"trusted":true},"execution_count":157,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}